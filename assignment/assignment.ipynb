{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzh-WMH7co3Z"
      },
      "source": [
        "# Assignment: Trees\n",
        "Do three questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rIIJl8uco3a"
      },
      "source": [
        "**Q1.** Please answer the following questions in your own words.\n",
        "\n",
        "1. How are trees constructed?\n",
        "\n",
        "2. How do trees handle non-linear relationships between variables? Compare this to linear models.\n",
        "\n",
        "3. Why is the Gini a good loss function for categorical target variables?\n",
        "\n",
        "4. Why do trees tend to overfit, and how can this tendency be constrained?\n",
        "\n",
        "5. True or false, and explain: Trees only really perform well in situations with lots of categorical variables as features/covariates.\n",
        "\n",
        "6. Why don't most versions of classification/regression tree concept allow for more than two branches after a split?\n",
        "\n",
        "7. What are some heuristic ways you can examine a tree and decide whether it is probably over- or under-fitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Q1 Answers***\n",
        "\n",
        "1. Trees are constructued through the continuous splitting of parameters in order to refine one's way of acquiring the most accurate/statisitically comprehensive value.\n",
        "\n",
        "2. Tree takes the features of value and split them into regions, without making assumptions on that data. Linear models try to a line through the model which requires engineering the linearity.\n",
        "\n",
        "3. Gini is good for categorical targets because it helps decision trees find splits that create pure class groupings, which is exactly what's needed for accurate classification.\n",
        "\n",
        "4. Trees can just continue to split until finding a perfect fit for the data. It also can accidentally memorize training data instead of learning from it. You can limit tree depth, and incorporate random forests to reduce overfitting through averaging.\n",
        "\n",
        "5. False, trees can perform well with both numerical and categorical variables as features. The performance of decision trees is more dependent on other factors like the quality of the data, the complexity of the model, and the algorithm's tuning (like depth of the tree).\n",
        "\n",
        "6. Most versions of classification and regression trees limit splits to 2 branches after a split because of how they are designed to simplify the decision-making process and optimize for both efficiency and interpretability. This is largely down to binary splits being much more simple, computational efficiency, and it simplifying the learning process.\n",
        "\n",
        "7. You can look at the depth or size of the tree (for example, if the tree has lots of levels and super complex, it's probably overfitting. If it's really shallow and does not capture enough of the data's variability, it's underfitting)."
      ],
      "metadata": {
        "id": "zIudQWSJcuy3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C37KmEL_co3a"
      },
      "source": [
        "**Q2.** This is a case study on regression and classification trees.\n",
        "\n",
        "1. Load `./data/cars_hw.csv`. How many observations and features/covariates/variables? What are the available variables? Take a look at the first few rows of data.\n",
        "\n",
        "2. For the categorical variables `Make`, `Color`, `Body_type`, `No_of_Owners`, `Fuel_Type`, `Transmission`, and `Transmission_Type`, create dummy/one-hot-encoded representations. For numeric variables, we'll use `Mileage_Run`, `Make_Year`, and `Seating_Capacity`. Our target variable will be `Price`. Make a train-test split of your data.\n",
        "\n",
        "3. From `sklearn.tree`, import the `DecisionTreeRegressor` and `plot_tree`. Use a train-test split to iterate over possible values for `min_samples_leaf`, computing the $R^2$ for each value between 1 and 25. What choice achieves the highest $R^2$ on the test data?\n",
        "\n",
        "4. For the optimal `min_samples_leaf` from 3, regress price on the rest of the features/covariates using the training data. What is your $R^2$ and RMSE on the test set? Plot the dendrogram. Plot the residuals. Is the density of residuals symmetric and centered around 0?\n",
        "\n",
        "4. Run a linear regression of price on the same variables. Which model -- regression tree or linear regression -- performs better on the test set? Why?\n",
        "\n",
        "5. Predict prices using both your tree and your linear model, and make a scatter plot of their values. Describe what you see."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "cars_df = pd.read_csv('https://raw.githubusercontent.com/ezraattisso/linearModels/refs/heads/main/data/cars_hw.csv')\n",
        "cars_df.head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "_MRWbnpniDxs",
        "outputId": "bb6162b4-4037-4d9d-b321-6f768362dc8e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0        Make  Make_Year   Color  Body_Type  Mileage_Run  \\\n",
              "0           1  Volkswagen       2017  silver      sedan        44611   \n",
              "1           2     Hyundai       2016     red  crossover        20305   \n",
              "2           3       Honda       2019   white        suv        29540   \n",
              "3           4     Renault       2017  bronze  hatchback        35680   \n",
              "4           5     Hyundai       2017  orange  hatchback        25126   \n",
              "\n",
              "  No_of_Owners  Seating_Capacity Fuel_Type Transmission Transmission_Type  \\\n",
              "0          1st                 5    diesel      7-Speed         Automatic   \n",
              "1          1st                 5    petrol      5-Speed            Manual   \n",
              "2          2nd                 5    petrol      5-Speed            Manual   \n",
              "3          1st                 5    petrol      5-Speed            Manual   \n",
              "4          1st                 5    petrol      5-Speed            Manual   \n",
              "\n",
              "    Price  \n",
              "0  657000  \n",
              "1  682000  \n",
              "2  793000  \n",
              "3  414000  \n",
              "4  515000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56fa8f4e-1427-4c84-910f-27cac4fb64ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Make</th>\n",
              "      <th>Make_Year</th>\n",
              "      <th>Color</th>\n",
              "      <th>Body_Type</th>\n",
              "      <th>Mileage_Run</th>\n",
              "      <th>No_of_Owners</th>\n",
              "      <th>Seating_Capacity</th>\n",
              "      <th>Fuel_Type</th>\n",
              "      <th>Transmission</th>\n",
              "      <th>Transmission_Type</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Volkswagen</td>\n",
              "      <td>2017</td>\n",
              "      <td>silver</td>\n",
              "      <td>sedan</td>\n",
              "      <td>44611</td>\n",
              "      <td>1st</td>\n",
              "      <td>5</td>\n",
              "      <td>diesel</td>\n",
              "      <td>7-Speed</td>\n",
              "      <td>Automatic</td>\n",
              "      <td>657000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Hyundai</td>\n",
              "      <td>2016</td>\n",
              "      <td>red</td>\n",
              "      <td>crossover</td>\n",
              "      <td>20305</td>\n",
              "      <td>1st</td>\n",
              "      <td>5</td>\n",
              "      <td>petrol</td>\n",
              "      <td>5-Speed</td>\n",
              "      <td>Manual</td>\n",
              "      <td>682000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Honda</td>\n",
              "      <td>2019</td>\n",
              "      <td>white</td>\n",
              "      <td>suv</td>\n",
              "      <td>29540</td>\n",
              "      <td>2nd</td>\n",
              "      <td>5</td>\n",
              "      <td>petrol</td>\n",
              "      <td>5-Speed</td>\n",
              "      <td>Manual</td>\n",
              "      <td>793000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Renault</td>\n",
              "      <td>2017</td>\n",
              "      <td>bronze</td>\n",
              "      <td>hatchback</td>\n",
              "      <td>35680</td>\n",
              "      <td>1st</td>\n",
              "      <td>5</td>\n",
              "      <td>petrol</td>\n",
              "      <td>5-Speed</td>\n",
              "      <td>Manual</td>\n",
              "      <td>414000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Hyundai</td>\n",
              "      <td>2017</td>\n",
              "      <td>orange</td>\n",
              "      <td>hatchback</td>\n",
              "      <td>25126</td>\n",
              "      <td>1st</td>\n",
              "      <td>5</td>\n",
              "      <td>petrol</td>\n",
              "      <td>5-Speed</td>\n",
              "      <td>Manual</td>\n",
              "      <td>515000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56fa8f4e-1427-4c84-910f-27cac4fb64ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-56fa8f4e-1427-4c84-910f-27cac4fb64ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-56fa8f4e-1427-4c84-910f-27cac4fb64ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8879fb2a-001b-4960-82b7-29d5daf5af2e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8879fb2a-001b-4960-82b7-29d5daf5af2e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8879fb2a-001b-4960-82b7-29d5daf5af2e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cars_df",
              "summary": "{\n  \"name\": \"cars_df\",\n  \"rows\": 976,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 281,\n        \"min\": 1,\n        \"max\": 976,\n        \"num_unique_values\": 976,\n        \"samples\": [\n          200,\n          542,\n          175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Make\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"Volkswagen\",\n          \"Hyundai\",\n          \"Chevrolet\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Make_Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2011,\n        \"max\": 2022,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2011,\n          2014,\n          2017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Color\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"brown\",\n          \"black\",\n          \"silver\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Body_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"crossover\",\n          \"muv\",\n          \"suv\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mileage_Run\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24390,\n        \"min\": 1117,\n        \"max\": 99495,\n        \"num_unique_values\": 878,\n        \"samples\": [\n          16240,\n          23724,\n          43273\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"No_of_Owners\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"1st\",\n          \"2nd\",\n          \"3rd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Seating_Capacity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 4,\n        \"max\": 8,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7,\n          4,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fuel_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"diesel\",\n          \"petrol\",\n          \"petrol+cng\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transmission\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"5-Speed\",\n          \"4-Speed\",\n          \"6-Speed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transmission_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Manual\",\n          \"Automatic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 367323,\n        \"min\": 188000,\n        \"max\": 2941000,\n        \"num_unique_values\": 585,\n        \"samples\": [\n          423000,\n          290000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q2.2\n",
        "\n",
        "categorical_cols = ['Make', 'Color', 'Body_Type', 'No_of_Owners', 'Fuel_Type', 'Transmission', 'Transmission_Type']\n",
        "numerical_cols = ['Mileage_Run', 'Make_Year', 'Seating_Capacity']\n",
        "target_col = 'Price'\n",
        "\n",
        "cars_dummies = pd.get_dummies(cars_df[categorical_cols], drop_first=True)\n",
        "\n",
        "# wanting to combine the categoricals with the numerical features here.\n",
        "X = pd.concat([cars_df[numerical_cols], cars_dummies], axis=1)\n",
        "y = cars_df[target_col]\n",
        "\n",
        "\n",
        "# Creatign the train-test split here.\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# verifying the shape.\n",
        "print(\"\\nTraining set shape:\", X_train.shape)\n",
        "print(\"Test set shape:\", X_test.shape)\n",
        "print(\"Training target shape:\", y_train.shape)\n",
        "print(\"Test target shape:\", y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyFiPWQDitKp",
        "outputId": "1433e19d-72ab-47a1-dec7-fa33d16c196c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training set shape: (780, 45)\n",
            "Test set shape: (196, 45)\n",
            "Training target shape: (780,)\n",
            "Test target shape: (196,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q2.3\n",
        "\n",
        "# Listing to store R² scores for different min_samples_leaf values.\n",
        "min_samples_leaf_values = range(1, 26)\n",
        "r2_scores = []\n",
        "\n",
        "# Iterating over a bunch of possible values for min_samples_leaf.\n",
        "for min_leaf in min_samples_leaf_values:\n",
        "    dt_model = DecisionTreeRegressor(min_samples_leaf=min_leaf, random_state=42)\n",
        "    dt_model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = dt_model.predict(X_test) # Making predictions on test set.\n",
        "    r2 = r2_score(y_test, y_pred) # Calculating the R² score\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    print(f\"min_samples_leaf = {min_leaf}, R² = {r2:.4f}\")\n",
        "\n",
        "# Finding the best min_samples_leaf value here.\n",
        "best_min_samples_leaf = min_samples_leaf_values[r2_scores.index(max(r2_scores))]\n",
        "best_r2 = max(r2_scores)\n",
        "\n",
        "print(f\"\\nBest min_samples_leaf value: {best_min_samples_leaf}\")\n",
        "print(f\"Highest R² score on test data: {best_r2:.4f}\")\n",
        "\n",
        "# Plotting R² scores vs min_samples_leaf values.\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(min_samples_leaf_values, r2_scores, marker='o')\n",
        "plt.xlabel('min_samples_leaf')\n",
        "plt.ylabel('R² Score on Test Data')\n",
        "plt.title('R² Score vs min_samples_leaf')\n",
        "plt.grid(True)\n",
        "plt.axvline(x=best_min_samples_leaf, color='red', linestyle='--',\n",
        "           label=f'Best value: {best_min_samples_leaf}')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Training the best model here.\n",
        "best_model = DecisionTreeRegressor(min_samples_leaf=best_min_samples_leaf, random_state=42)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Here I want to visualize the best tree (only if it's not too large).\n",
        "if best_model.tree_.node_count < 50:  # keeping plot small.\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    plot_tree(best_model, feature_names=X_train.columns, filled=True, rounded=True)\n",
        "    plt.title(f\"Decision Tree with min_samples_leaf = {best_min_samples_leaf}\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Tree is too large to visualize effectively\")\n",
        "\n"
      ],
      "metadata": {
        "id": "pOag_Ub7j5eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Q2.4\n",
        "\n",
        "# Training the decision tree regressor with the optimal min_samples_leaf\n",
        "optimal_dt = DecisionTreeRegressor(min_samples_leaf=best_min_samples_leaf, random_state=42)\n",
        "optimal_dt.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = optimal_dt.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(f\"Test set R²: {r2:.4f}\")\n",
        "print(f\"Test set RMSE: {rmse:.2f}\")\n",
        "\n",
        "# Plotting the dendogram decision tree.\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(optimal_dt, feature_names=X_train.columns, filled=True, rounded=True,\n",
        "          fontsize=10, max_depth=3)\n",
        "plt.title(f\"Decision Tree with min_samples_leaf = {best_min_samples_leaf} (Limited to depth 3)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculating and plotting the residuals.\n",
        "residuals = y_test - y_pred\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Subplot 1: Residuals vs Predicted values\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.scatter(y_pred, residuals, alpha=0.5)\n",
        "plt.axhline(y=0, color='r', linestyle='-')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals vs Predicted Values')\n",
        "plt.grid(True)\n",
        "\n",
        "# Subplot 2: Distribution of residuals\n",
        "plt.subplot(2, 1, 2)\n",
        "sns.histplot(residuals, kde=True)\n",
        "plt.axvline(x=0, color='r', linestyle='-')\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Residuals')\n",
        "plt.grid(True)\n",
        "\n",
        "mean_residuals = np.mean(residuals)\n",
        "median_residuals = np.median(residuals)\n",
        "plt.annotate(f'Mean: {mean_residuals:.2f}\\nMedian: {median_residuals:.2f}',\n",
        "             xy=(0.7, 0.8), xycoords='axes fraction')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Mean of residuals: {mean_residuals:.4f}\")\n",
        "print(f\"Median of residuals: {median_residuals:.4f}\")\n",
        "print(f\"Skewness of residuals: {residuals.skew():.4f}\")\n",
        "\n",
        "\n",
        "## Slightly skewed to the right of 0 but overall still symmetric."
      ],
      "metadata": {
        "id": "22H0UUPSmYYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Q2.5\n",
        "\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "lr_pred = lr_model.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics for linear regression\n",
        "lr_r2 = r2_score(y_test, lr_pred)\n",
        "lr_rmse = np.sqrt(mean_squared_error(y_test, lr_pred))\n",
        "\n",
        "# Get the decision tree metrics for comparison (from previous model)\n",
        "dt_r2 = r2\n",
        "dt_rmse = rmse\n",
        "\n",
        "print(\"Model Performance Comparison:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Linear Regression:\")\n",
        "print(f\"  R² Score: {lr_r2:.4f}\")\n",
        "print(f\"  RMSE: {lr_rmse:.2f}\")\n",
        "print(f\"Decision Tree (min_samples_leaf={best_min_samples_leaf}):\")\n",
        "print(f\"  R² Score: {dt_r2:.4f}\")\n",
        "print(f\"  RMSE: {dt_rmse:.2f}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Calculate the residuals for linear regression\n",
        "lr_residuals = y_test - lr_pred\n",
        "\n",
        "# Compare the residuals of both models\n",
        "plt.figure(figsize=(14, 10))\n",
        "\n",
        "# Residuals vs Predicted Values for both models\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.scatter(lr_pred, lr_residuals, alpha=0.5, color='blue', label='Linear Regression')\n",
        "plt.axhline(y=0, color='r', linestyle='-')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Linear Regression: Residuals vs Predicted')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.scatter(y_pred, residuals, alpha=0.5, color='green', label='Decision Tree')\n",
        "plt.axhline(y=0, color='r', linestyle='-')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Decision Tree: Residuals vs Predicted')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# Distribution of residuals for both models\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.histplot(lr_residuals, kde=True, color='blue')\n",
        "plt.axvline(x=0, color='r', linestyle='-')\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Linear Regression: Distribution of Residuals')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.histplot(residuals, kde=True, color='green')\n",
        "plt.axvline(x=0, color='r', linestyle='-')\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Decision Tree: Distribution of Residuals')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Residual Statistics:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"Linear Regression:\")\n",
        "print(f\"  Mean of residuals: {np.mean(lr_residuals):.4f}\")\n",
        "print(f\"  Median of residuals: {np.median(lr_residuals):.4f}\")\n",
        "print(f\"  Skewness of residuals: {pd.Series(lr_residuals).skew():.4f}\")\n",
        "print(\"Decision Tree:\")\n",
        "print(f\"  Mean of residuals: {np.mean(residuals):.4f}\")\n",
        "print(f\"  Median of residuals: {np.median(residuals):.4f}\")\n",
        "print(f\"  Skewness of residuals: {pd.Series(residuals).skew():.4f}\")"
      ],
      "metadata": {
        "id": "w2viX4wQmnJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Q2.6\n",
        "\n",
        "# Got predictions from both models here.\n",
        "dt_predictions = y_pred  # From the decision tree model\n",
        "lr_predictions = lr_pred  # From the linear regression model\n",
        "\n",
        "# Creating a scatter plot of the predictions.\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(dt_predictions, lr_predictions, alpha=0.7)\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')  # Add a diagonal line\n",
        "\n",
        "plt.xlabel('Decision Tree Predictions')\n",
        "plt.ylabel('Linear Regression Predictions')\n",
        "plt.title('Comparison of Price Predictions: Decision Tree vs Linear Regression')\n",
        "plt.grid(True)\n",
        "\n",
        "correlation = np.corrcoef(dt_predictions, lr_predictions)[0, 1]\n",
        "plt.annotate(f'Correlation: {correlation:.4f}',\n",
        "             xy=(0.05, 0.95), xycoords='axes fraction',\n",
        "             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
        "mean_abs_diff = np.mean(np.abs(dt_predictions - lr_predictions))\n",
        "plt.annotate(f'Mean Absolute Difference: {mean_abs_diff:.2f}',\n",
        "             xy=(0.05, 0.89), xycoords='axes fraction',\n",
        "             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# histogram of the differences between predictions.\n",
        "plt.figure(figsize=(10, 6))\n",
        "diff = dt_predictions - lr_predictions\n",
        "plt.hist(diff, bins=30, alpha=0.7)\n",
        "plt.axvline(x=0, color='r', linestyle='--')\n",
        "plt.xlabel('Decision Tree Predictions - Linear Regression Predictions')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Differences Between Model Predictions')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Min difference: {np.min(diff):.2f}\")\n",
        "print(f\"Max difference: {np.max(diff):.2f}\")\n",
        "print(f\"Mean difference: {np.mean(diff):.2f}\")\n",
        "print(f\"Median difference: {np.median(diff):.2f}\")\n",
        "print(f\"Standard deviation of differences: {np.std(diff):.2f}\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.scatter(y_test, dt_predictions, alpha=0.7, color='green')\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')\n",
        "plt.xlabel('Actual Prices')\n",
        "plt.ylabel('Decision Tree Predictions')\n",
        "plt.title('Decision Tree: Predicted vs Actual')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.scatter(y_test, lr_predictions, alpha=0.7, color='blue')\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')\n",
        "plt.xlabel('Actual Prices')\n",
        "plt.ylabel('Linear Regression Predictions')\n",
        "plt.title('Linear Regression: Predicted vs Actual')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "## Both the decision tree and the linear regression plots are showing nearly identical plots.\n"
      ],
      "metadata": {
        "id": "9TcbS7grn_Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdAm1Vevco3b"
      },
      "source": [
        "**Q3.** This is a case study about classification and regression trees.\n",
        "\n",
        "1. Load the `Breast Cancer METABRIC.csv` dataset. How many observations and variables does it contain? Print out the first few rows of data.\n",
        "\n",
        "2.  We'll use a consistent set of feature/explanatory variables. For numeric variables, we'll include `Tumor Size`, `Lymph nodes examined positive`, `Age at Diagnosis`. For categorical variables, we'll include `Tumor Stage`, `Chemotherapy`, and `Cancer Type Detailed`. One-hot-encode the categorical variables and concatenate them with the numeric variables into a feature/covariate matrix, $X$.\n",
        "\n",
        "3. Let's predict `Overall Survival Status` given the features/covariates $X$. There are 528 missing values, unfortunately: Either drop those rows from your data or add them as a category to predict. Constrain the minimum samples per leaf to 10. Print a dendrogram of the tree. Print a confusion matrix of the algorithm's performance. What is the accuracy?\n",
        "\n",
        "4. For your model in part three, compute three statistics:\n",
        "    - The **true positive rate** or **sensitivity**:\n",
        "        $$\n",
        "        TPR = \\dfrac{TP}{TP+FN}\n",
        "        $$\n",
        "    - The **true negative rate** or **specificity**:\n",
        "        $$\n",
        "        TNR = \\dfrac{TN}{TN+FP}\n",
        "        $$\n",
        "    Does your model tend to perform better with respect to one of these metrics?\n",
        "\n",
        "5. Let's predict `Overall Survival (Months)` given the features/covariates $X$. Use the train/test split to pick the optimal `min_samples_leaf` value that gives the highest $R^2$ on the test set (it's about 110). What is the $R^2$? Plot the test values against the predicted values. How do you feel about this model for clinical purposes?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q3.1\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "cancer_df = pd.read_csv('https://raw.githubusercontent.com/ezraattisso/trees/refs/heads/main/assignment/data/Breast%20Cancer%20METABRIC.csv')\n",
        "cancer_df.head()\n"
      ],
      "metadata": {
        "id": "vynVLGTqpQob",
        "outputId": "de5fb7a2-4d95-44be-e2e7-77ab7e80b983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Patient ID  Age at Diagnosis Type of Breast Surgery    Cancer Type  \\\n",
              "0    MB-0000             75.65             Mastectomy  Breast Cancer   \n",
              "1    MB-0002             43.19      Breast Conserving  Breast Cancer   \n",
              "2    MB-0005             48.87             Mastectomy  Breast Cancer   \n",
              "3    MB-0006             47.68             Mastectomy  Breast Cancer   \n",
              "4    MB-0008             76.97             Mastectomy  Breast Cancer   \n",
              "\n",
              "                        Cancer Type Detailed Cellularity Chemotherapy  \\\n",
              "0           Breast Invasive Ductal Carcinoma         NaN           No   \n",
              "1           Breast Invasive Ductal Carcinoma        High           No   \n",
              "2           Breast Invasive Ductal Carcinoma        High          Yes   \n",
              "3  Breast Mixed Ductal and Lobular Carcinoma    Moderate          Yes   \n",
              "4  Breast Mixed Ductal and Lobular Carcinoma        High          Yes   \n",
              "\n",
              "  Pam50 + Claudin-low subtype  Cohort ER status measured by IHC  ...  \\\n",
              "0                 claudin-low     1.0                   Positve  ...   \n",
              "1                        LumA     1.0                   Positve  ...   \n",
              "2                        LumB     1.0                   Positve  ...   \n",
              "3                        LumB     1.0                   Positve  ...   \n",
              "4                        LumB     1.0                   Positve  ...   \n",
              "\n",
              "  Overall Survival Status  PR Status Radio Therapy  \\\n",
              "0                  Living   Negative           Yes   \n",
              "1                  Living   Positive           Yes   \n",
              "2                Deceased   Positive            No   \n",
              "3                  Living   Positive           Yes   \n",
              "4                Deceased   Positive           Yes   \n",
              "\n",
              "  Relapse Free Status (Months) Relapse Free Status     Sex  \\\n",
              "0                       138.65        Not Recurred  Female   \n",
              "1                        83.52        Not Recurred  Female   \n",
              "2                       151.28            Recurred  Female   \n",
              "3                       162.76        Not Recurred  Female   \n",
              "4                        18.55            Recurred  Female   \n",
              "\n",
              "  3-Gene classifier subtype Tumor Size Tumor Stage  Patient's Vital Status  \n",
              "0                 ER-/HER2-       22.0         2.0                  Living  \n",
              "1     ER+/HER2- High Prolif       10.0         1.0                  Living  \n",
              "2                       NaN       15.0         2.0         Died of Disease  \n",
              "3                       NaN       25.0         2.0                  Living  \n",
              "4     ER+/HER2- High Prolif       40.0         2.0         Died of Disease  \n",
              "\n",
              "[5 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b450f238-d68b-4ca7-b088-0c32bbddf3dc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Patient ID</th>\n",
              "      <th>Age at Diagnosis</th>\n",
              "      <th>Type of Breast Surgery</th>\n",
              "      <th>Cancer Type</th>\n",
              "      <th>Cancer Type Detailed</th>\n",
              "      <th>Cellularity</th>\n",
              "      <th>Chemotherapy</th>\n",
              "      <th>Pam50 + Claudin-low subtype</th>\n",
              "      <th>Cohort</th>\n",
              "      <th>ER status measured by IHC</th>\n",
              "      <th>...</th>\n",
              "      <th>Overall Survival Status</th>\n",
              "      <th>PR Status</th>\n",
              "      <th>Radio Therapy</th>\n",
              "      <th>Relapse Free Status (Months)</th>\n",
              "      <th>Relapse Free Status</th>\n",
              "      <th>Sex</th>\n",
              "      <th>3-Gene classifier subtype</th>\n",
              "      <th>Tumor Size</th>\n",
              "      <th>Tumor Stage</th>\n",
              "      <th>Patient's Vital Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MB-0000</td>\n",
              "      <td>75.65</td>\n",
              "      <td>Mastectomy</td>\n",
              "      <td>Breast Cancer</td>\n",
              "      <td>Breast Invasive Ductal Carcinoma</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>claudin-low</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Positve</td>\n",
              "      <td>...</td>\n",
              "      <td>Living</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Yes</td>\n",
              "      <td>138.65</td>\n",
              "      <td>Not Recurred</td>\n",
              "      <td>Female</td>\n",
              "      <td>ER-/HER2-</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Living</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MB-0002</td>\n",
              "      <td>43.19</td>\n",
              "      <td>Breast Conserving</td>\n",
              "      <td>Breast Cancer</td>\n",
              "      <td>Breast Invasive Ductal Carcinoma</td>\n",
              "      <td>High</td>\n",
              "      <td>No</td>\n",
              "      <td>LumA</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Positve</td>\n",
              "      <td>...</td>\n",
              "      <td>Living</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Yes</td>\n",
              "      <td>83.52</td>\n",
              "      <td>Not Recurred</td>\n",
              "      <td>Female</td>\n",
              "      <td>ER+/HER2- High Prolif</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Living</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MB-0005</td>\n",
              "      <td>48.87</td>\n",
              "      <td>Mastectomy</td>\n",
              "      <td>Breast Cancer</td>\n",
              "      <td>Breast Invasive Ductal Carcinoma</td>\n",
              "      <td>High</td>\n",
              "      <td>Yes</td>\n",
              "      <td>LumB</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Positve</td>\n",
              "      <td>...</td>\n",
              "      <td>Deceased</td>\n",
              "      <td>Positive</td>\n",
              "      <td>No</td>\n",
              "      <td>151.28</td>\n",
              "      <td>Recurred</td>\n",
              "      <td>Female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Died of Disease</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MB-0006</td>\n",
              "      <td>47.68</td>\n",
              "      <td>Mastectomy</td>\n",
              "      <td>Breast Cancer</td>\n",
              "      <td>Breast Mixed Ductal and Lobular Carcinoma</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>LumB</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Positve</td>\n",
              "      <td>...</td>\n",
              "      <td>Living</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Yes</td>\n",
              "      <td>162.76</td>\n",
              "      <td>Not Recurred</td>\n",
              "      <td>Female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Living</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MB-0008</td>\n",
              "      <td>76.97</td>\n",
              "      <td>Mastectomy</td>\n",
              "      <td>Breast Cancer</td>\n",
              "      <td>Breast Mixed Ductal and Lobular Carcinoma</td>\n",
              "      <td>High</td>\n",
              "      <td>Yes</td>\n",
              "      <td>LumB</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Positve</td>\n",
              "      <td>...</td>\n",
              "      <td>Deceased</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Yes</td>\n",
              "      <td>18.55</td>\n",
              "      <td>Recurred</td>\n",
              "      <td>Female</td>\n",
              "      <td>ER+/HER2- High Prolif</td>\n",
              "      <td>40.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Died of Disease</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b450f238-d68b-4ca7-b088-0c32bbddf3dc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b450f238-d68b-4ca7-b088-0c32bbddf3dc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b450f238-d68b-4ca7-b088-0c32bbddf3dc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f64ae05c-02d0-45ab-bb1d-a64ab41234dd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f64ae05c-02d0-45ab-bb1d-a64ab41234dd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f64ae05c-02d0-45ab-bb1d-a64ab41234dd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cancer_df"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q3.2\n",
        "\n",
        "numeric_features = ['Tumor Size', 'Lymph nodes examined positive', 'Age at Diagnosis']\n",
        "X_numeric = cancer_df[numeric_features]\n",
        "\n",
        "categorical_features = ['Tumor Stage', 'Chemotherapy', 'Cancer Type Detailed']\n",
        "X_categorical = cancer_df[categorical_features]\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
        "X_categorical_encoded = encoder.fit_transform(X_categorical)\n",
        "\n",
        "# Getting the feature names after one-hot encoding here.\n",
        "encoded_feature_names = []\n",
        "for i, feature in enumerate(categorical_features):\n",
        "    categories = encoder.categories_[i][1:]  # Skip the first category that was dropped\n",
        "    for category in categories:\n",
        "        encoded_feature_names.append(f\"{feature}_{category}\")\n",
        "\n",
        "# Converting the encoded categorical data to a DataFrame with appropriate column names.\n",
        "X_categorical_df = pd.DataFrame(X_categorical_encoded, columns=encoded_feature_names, index=cancer_df.index)\n",
        "\n",
        "# Concatenating the numeric and encoded categorical features into the final feature matrix X.\n",
        "X = pd.concat([X_numeric, X_categorical_df], axis=1)\n",
        "\n",
        "print(f\"Shape of feature matrix X: {X.shape}\")\n",
        "print(\"Features included in X:\")\n",
        "for column in X.columns:\n",
        "    print(f\"- {column}\")\n"
      ],
      "metadata": {
        "id": "IazZqwBtpb63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Q3.3\n",
        "\n"
      ],
      "metadata": {
        "id": "YN86uGJPq0KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpt59Zfnco3b"
      },
      "source": [
        "**Q4.** This is a case study about trees using bond rating data. This is a dataset about bond ratings for different companies, alongside a bunch of business statistics and other data. Companies often have multiple reviews at different dates. We want to predict the bond rating (AAA, AA, A, BBB, BB, B, ..., C, D). Do business fundamentals predict the company's rating?\n",
        "\n",
        "1. Load the `./data/corporate_ratings.csv` dataset. How many observations and variables does it contain? Print out the first few rows of data.\n",
        "\n",
        "2.  Plot a histogram of the `ratings` variable. It turns out that the gradations of AAA/AA/A and BBB/BB/B and so on make it hard to get good results with trees. Collapse all AAA/AA/A ratings into just A, and similarly for B and C.\n",
        "\n",
        "3. Use all of the variables **except** Rating, Date, Name, Symbol, and Rating Agency Name. To include Sector, make a dummy/one-hot-encoded representation and include it in your features/covariates. Collect the relevant variables into a data matrix $X$.\n",
        "\n",
        "4. Do a train/test split of the data and use a decision tree classifier to predict the bond rating. Including a min_samples_leaf constraint can raise the accuracy and speed up computation time. Print a confusion matrix and the accuracy of your model. How well do you predict the different bond ratings?\n",
        "\n",
        "5. If you include the rating agency as a feature/covariate/predictor variable, do the results change? How do you interpret this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrTActuSco3b"
      },
      "source": [
        "**Q5.** This is a case study about detecting fraud using classification trees. The goal is to predict the `class` variable, which is 0 for non-fraud and 1 for fraud.\n",
        "\n",
        "1. Open `./data/creditcard_fraud.csv`. Print the number of observations and variables, and look at the first few rows of data. The variables are already normalized and de-identified, and are just called things like `V8` to protect the privacy of the clients.\n",
        "\n",
        "2. Print a table of counts for the `class` variable and make a histogram. What percentage of transactions are fraudulent?\n",
        "\n",
        "3. Drop `Time` and make a decision tree classifier to predict fraud. Print a confusion table and compute the accuracy. This is a serious **class imbalance** problem: The minority class is so small that essentially predicting 0's for all cases will achieve an extremely high accuracy. There are over-sampling techniques to deal with this issue, but we don't have time to cover them in class.\n",
        "\n",
        "4. Imagine that you block every transaction in the test set labelled as fraudulent. How much money is (1) saved that should be saved, (2) lost to fraud anyway, (3) withheld in error from customers? Does implementing this anti-fraud system seem like a good idea, or not? Why?\n",
        "\n",
        "5. Instead of predicting fraud, predict loss: Multiple the `Class` variable times the `Amount` variable, and call it `Loss`. Predict it using a decision tree regressor (making sure to drop Class, Time, and Loss from the features/covariates/predictors). What $R^2$ and RMSE do you get? Make a scatterplot of the predicted values on the test group versus the actual test values. Do you notice any interesting patterns? How could you use this algorithm to decide which transactions to block, and why?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "y6zwgs9Qco3b"
      },
      "source": [
        "**Q6.** Show that any decision tree is equivalent to a linear regression on a set of dummy variables that represent the optimal splits in the tree.\n",
        "\n",
        "Hint: You can think of CART as partitioning the feature space into a set of sets $\\{S_1, S_2, ..., S_K\\}$, and then predicting the average for all of the observations in each set $S_k$, $m_k$:\n",
        "$$\n",
        "\\hat{y}(x) = \\sum_{k=1}^K \\mathbb{I}\\{ x \\text{ is in } S_k \\} m_k\n",
        "$$\n",
        "where $\\mathbb{I} \\{ P(x,k)\\}$ takes the value 1 if the proposition $P(x,k)$ is true and 0 otherwise. Now, doesn't that look like least-squares regression on a set of dummy/one-hot-encoded variables?\n",
        "\n",
        "Conversely, can any linear regression be represented by a tree?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}